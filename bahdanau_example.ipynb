{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.de import German\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from tqdm import tqdm_notebook\n",
    "import tqdm\n",
    "from ipywidgets import FloatProgress\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# if torch.cuda.is_available:\n",
    "#     device = torch.device(\"cuda\")\n",
    "# else:\n",
    "    \n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, drop_prob=0):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=drop_prob, batch_first=True)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        # Embed input words\n",
    "        embedded = self.embedding(inputs)\n",
    "        # Pass the embedded word vectors into LSTM and return all outputs\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, drop_prob=0.1):\n",
    "        super(BahdanauDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        self.lstm = nn.LSTM(self.hidden_size*2, self.hidden_size, batch_first=True)\n",
    "        self.classifier = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden, encoder_outputs):\n",
    "        encoder_outputs = encoder_outputs.squeeze()\n",
    "        # Embed input words\n",
    "        embedded = self.embedding(inputs).view(1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        # Calculating Alignment Scores\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        alignment_scores = x.bmm(self.weight.unsqueeze(2))  \n",
    "\n",
    "        # Softmaxing alignment scores to get Attention weights\n",
    "        attn_weights = F.softmax(alignment_scores.view(1,-1), dim=1)\n",
    "\n",
    "        # Multiplying the Attention weights with encoder outputs to get the context vector\n",
    "        context_vector = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        # Concatenating context vector with embedded input word\n",
    "        output = torch.cat((embedded, context_vector[0]), 1).unsqueeze(0)\n",
    "        # Passing the concatenated vector as input to the LSTM cell\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        # Passing the LSTM output through a Linear layer acting as a classifier\n",
    "        output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069e8f7eb65c466f818eb1be19f9b1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the English-German sentences pairs from the file\n",
    "with open(\"data/diffs/train/train.small.data\",\"r\") as file:\n",
    "    deu = [x for x in file.readlines()]\n",
    "en = []\n",
    "de = []\n",
    "for line in deu:\n",
    "    en.append(line.split(\"\\t\")[0])\n",
    "    de.append(line.split(\"\\t\")[1])\n",
    "    \n",
    "# Setting the number of training sentences we'll use\n",
    "training_examples = 20\n",
    "# We'll be using the spaCy's English and German tokenizers\n",
    "spacy_en = English()\n",
    "spacy_de = German()\n",
    "\n",
    "en_words = Counter()\n",
    "de_words = Counter()\n",
    "en_inputs = []\n",
    "de_inputs = []\n",
    "\n",
    "# Tokenizing the English and German sentences and creating our word banks for both languages\n",
    "for i in tqdm.notebook.tqdm(range(training_examples)):\n",
    "    en_tokens = spacy_en(en[i])\n",
    "    de_tokens = spacy_de(de[i])\n",
    "    if len(en_tokens)==0 or len(de_tokens)==0:\n",
    "        continue\n",
    "    for token in en_tokens:\n",
    "        en_words.update([token.text.lower()])\n",
    "    en_inputs.append([token.text.lower() for token in en_tokens])\n",
    "    for token in de_tokens:\n",
    "        de_words.update([token.text.lower()])\n",
    "    de_inputs.append([token.text.lower() for token in de_tokens])\n",
    "\n",
    "# Assigning an index to each word token, including the Start Of String(SOS), End Of String(EOS) and Unknown(UNK) tokens\n",
    "en_words = ['<sos>','<ens>','<unk>'] + sorted(en_words,key=en_words.get,reverse=True)\n",
    "en_w2i = {o:i for i,o in enumerate(en_words)}\n",
    "en_i2w = {i:o for i,o in enumerate(en_words)}\n",
    "de_words = ['<sos>','<eos>','<unk>'] + sorted(de_words,key=de_words.get,reverse=True)\n",
    "de_w2i = {o:i for i,o in enumerate(de_words)}\n",
    "de_i2w = {i:o for i,o in enumerate(de_words)}\n",
    "\n",
    "# Converting our English and German sentences to their token indexes\n",
    "for i in range(len(en_inputs)):\n",
    "    en_sentence = en_inputs[i]\n",
    "    de_sentence = de_inputs[i]\n",
    "    en_inputs[i] = [en_w2i[word] for word in en_sentence]\n",
    "    de_inputs[i] = [de_w2i[word] for word in de_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderLSTM(len(en_words), hidden_size).to(device)\n",
    "decoder = BahdanauDecoder(hidden_size, len(de_words)).to(device)\n",
    "\n",
    "lr = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 126\n"
     ]
    }
   ],
   "source": [
    "print(len(en_words), len(de_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b61abd6ed24c69bbcb23eccb163ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "teacher_forcing_prob = 1\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "tk0 = tqdm.notebook.tqdm(range(1,EPOCHS+1), total=EPOCHS)\n",
    "for epoch in tk0:\n",
    "    avg_loss = 0.\n",
    "    tk1 = tqdm.notebook.tqdm(enumerate(en_inputs),total=len(en_inputs),leave=False)\n",
    "    for i, sentence in tk1:\n",
    "        loss = 0.\n",
    "        h = encoder.init_hidden()\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        inp = torch.tensor(sentence).unsqueeze(0).to(device)\n",
    "        encoder_outputs, h = encoder(inp,h)\n",
    "        \n",
    "        #First decoder input will be the SOS token\n",
    "        decoder_input = torch.tensor([en_w2i['<sos>']], device=device)\n",
    "        #First decoder hidden state will be last encoder hidden state\n",
    "        decoder_hidden = h\n",
    "        output = []\n",
    "        teacher_forcing = True if random.random() < teacher_forcing_prob else False\n",
    "        \n",
    "        for ii in range(len(de_inputs[i])):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Get the index value of the word with the highest score from the decoder output\n",
    "            top_value, top_index = decoder_output.topk(1)\n",
    "            if teacher_forcing:\n",
    "                decoder_input = torch.tensor([de_inputs[i][ii]],device=device)\n",
    "            else:\n",
    "                decoder_input = torch.tensor([top_index.item()],device=device)\n",
    "            output.append(top_index.item())\n",
    "            # Calculate the loss of the prediction against the actual word\n",
    "            loss += F.nll_loss(decoder_output.view(1,-1), torch.tensor([de_inputs[i][ii]],device=device))\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        avg_loss += loss.item()/len(en_inputs)\n",
    "    tk0.set_postfix(loss=avg_loss)\n",
    "#   # Save model after every epoch (Optional)\n",
    "# torch.save({\"encoder\":encoder.state_dict(),\n",
    "#             \"decoder\":decoder.state_dict(),\n",
    "#             \"e_optimizer\":encoder_optimizer.state_dict(),\n",
    "#             \"d_optimizer\":decoder_optimizer},\n",
    "#            \"./model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
